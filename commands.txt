dws-15.informatik.uni-mannheim.de
tmux new -s uq4ppm
conda activate graphgps
conda activate card
tmux attach-session -t uq4ppm


bash training_scripts/run_ppm_HelpDesk.sh


python preprocess.py --datasets HelpDesk
python main.py --dataset HelpDesk --model dalstm --UQ deterministic --split_mode holdout --seed 42 --device 0
python main.py --dataset HelpDesk --model dalstm --UQ DA --split_mode holdout --seed 42 --device 0
python main.py --dataset HelpDesk --model dalstm --UQ CDA --split_mode holdout --seed 42 --device 0
python main.py --dataset HelpDesk --model dalstm --UQ DA_A --split_mode holdout --seed 42 --device 0
python main.py --dataset HelpDesk --model dalstm --UQ CDA_A --split_mode holdout --seed 42 --device 0
python evaluation.py --dataset HelpDesk --model dalstm




Which options are available for training and evaluation configuration?
Backbone model architecture: dalstm, pt, pgtnet
Uncertainty quantification methods:
1) deterministic: provides point estimates
2) DA: dropout approximation
3) CDA: concrete dropout approximation
4) DA_A: dropout approximation accomponied by aleatoric uncertainty quantification
5) CDA_A: concrete dropout approximation accomponied by aleatoric uncertainty quantification
6) CARD: classification and regression diffusion models
	
laplace-post-hoc: LA is constructed based on the deterministic pre-trained model
laplace-joint: LA is used to Jointly optimize MAP and hyperparameters

loss functions: mae or rmse or mse or LogCoshLoss or Huber or smooth_mae 
optimizers: NAdam/AdamW/Adam/RAdam/SGD





