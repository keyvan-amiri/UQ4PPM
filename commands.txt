dws-15.informatik.uni-mannheim.de
tmux new -s uq4ppm
conda activate graphgps
tmux attach-session -t uq4ppm

python preprocess.py --datasets env_permit
python main.py --dataset env_permit --model dalstm --UQ deterministic --split holdout --seed 42 --device 0
python main.py --dataset env_permit --model dalstm --UQ DA --split holdout --seed 42 --device 0
python main.py --dataset env_permit --model dalstm --UQ CDA --split holdout --seed 42 --device 0
python main.py --dataset env_permit --model dalstm --UQ DA_A --split holdout --seed 42 --device 0
python main.py --dataset env_permit --model dalstm --UQ CDA_A --split holdout --seed 42 --device 0




Which options are available for training and evaluation configuration?
Backbone model architecture: dalstm, cnn, pgtnet
Uncertainty quantification methods:
1) deterministic: provides point estimates
2) DA: dropout approximation
3) CDA: concrete dropout approximation
4) DA_A: dropout approximation accomponied by aleatoric uncertainty quantification
5) CDA_A: concrete dropout approximation accomponied by aleatoric uncertainty quantification
6) CARD: classification and regression diffusion models
	
laplace-post-hoc: LA is constructed based on the deterministic pre-trained model
laplace-joint: LA is used to Jointly optimize MAP and hyperparameters

loss functions: mae or rmse or mse or LogCoshLoss or Huber or smooth_mae 
optimizers: NAdam/AdamW/Adam/RAdam/SGD





