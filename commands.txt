dws-15.informatik.uni-mannheim.de
tmux new -s uq4ppm
conda activate graphgps   (only for PGTNet, evaluation and recalibration)
conda activate card	  (for train and test)
tmux attach-session -t uq4ppm

Pre-processing
python preprocess.py --datasets HelpDesk Sepsis BPIC12 BPIC13I BPIC15_1 BPIC20DD BPIC20ID BPIC20PTC BPIC20RFP BPIC20TPD --model dalstm
python comparison.py --dataset HelpDesk --model dalstm
python comparison.py --dataset Sepsis --model dalstm
python comparison.py --dataset BPIC15_1 --model dalstm
python comparison.py --dataset BPIC20TPD --model dalstm

python MixGaussian.py --cfg HelpDesk_GMM.yaml
python MixGaussian.py --cfg BPIC20TPD_GMM.yaml 
python MixGaussian.py --cfg BPIC20TPD_GMM.yaml --style dynamic 

train and test:
bash bash_scripts/01Experiment-1.sh
bash bash_scripts/02Experiment-2.sh
bash bash_scripts/03Experiment-3.sh
bash bash_scripts/04Experiment-4.sh


bash bash_scripts/Experiment-3.sh
bash bash_scripts/Experiment-4.sh



bash bash_scripts/RF.sh



evaluation:
bash bash_scripts/evaluation.sh

recalibration:
bash bash_scripts/recalibration_HelpDesk.sh



initial work on PGTNet:
python deterministic_pgtnet.py --cfg cfg/pgtnet_env_permit_GPS+SNMLP+RWSE.yaml seed 42



Which options are available for training and evaluation configuration?
Backbone model architecture: dalstm, pt, pgtnet
Uncertainty quantification methods:
1) deterministic: provides point estimates
2) DA: dropout approximation
3) CDA: concrete dropout approximation
4) DA_A: dropout approximation accomponied by aleatoric uncertainty quantification
5) CDA_A: concrete dropout approximation accomponied by aleatoric uncertainty quantification
6) CARD: classification and regression diffusion models
	
laplace-post-hoc: LA is constructed based on the deterministic pre-trained model
laplace-joint: LA is used to Jointly optimize MAP and hyperparameters

loss functions: mae or rmse or mse or LogCoshLoss or Huber or smooth_mae 
optimizers: NAdam/AdamW/Adam/RAdam/SGD












