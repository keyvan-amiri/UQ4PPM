data:
  normalization: False
uncertainty:
  ensemble:
    num_models: [3, 4, 5, 6, 7, 8, 9, 10]
    Bootstrapping_ratio: [0.25]
HPO_metric: nll # nll mae rmse sharp crps
HPO_radom_ratio: 1.0
calibration_type: all # all miscal rms ma isotonic
model:
  lstm:
    n_layers: 2
    hidden_size: 150 
    dropout: True
    dropout_prob: 0.1
train:
  loss_function: mae   
  max_epochs: 200
  batch_size: 64
  early_stop: True
  early_stop.patience: 50
  early_stop.min_delta: 0
optimizer:
  type: NAdam
  base_lr: 0.001 
  eps: 1e-7  
  weight_decay: 0.01 
evaluation:
  batch_size: 64
    